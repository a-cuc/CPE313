{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2c6556",
   "metadata": {},
   "source": [
    "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
    "--- | ---\n",
    "Course Code: | CPE 313\n",
    "Code Title: | Advanced Machine Learning and Deep Learning\n",
    "2nd Semester | AY 2024-2025\n",
    "<u>**Hands-on Activity 3.1** | **Convolutional Neural Network**\n",
    "**Name** | Cu, Angelo Luis C.\n",
    "**Section** | CPE32S3\n",
    "**Date Performed**: | 3/31/2025\n",
    "**Date Submitted**: | 3/31/2025\n",
    "**Instructor**: | Engr. Roman Richard\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-trainer",
   "metadata": {},
   "source": [
    "# Activity 2.1 : Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-manner",
   "metadata": {},
   "source": [
    "#### Objective(s):\n",
    "\n",
    "This activity aims to introduce how to build a convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-transport",
   "metadata": {},
   "source": [
    "#### Intended Learning Outcomes (ILOs):\n",
    "* Demonstrate how to build and train convolutional neural network \n",
    "* Evaluate the accuracy and loss of the model using convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-providence",
   "metadata": {},
   "source": [
    "#### Resources:\n",
    "* Jupyter Notebook\n",
    "* CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-trail",
   "metadata": {},
   "source": [
    "#### Procedures\n",
    "Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stretch-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-seating",
   "metadata": {},
   "source": [
    "* Shuffle the data\n",
    "* Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modular-springer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-carolina",
   "metadata": {},
   "source": [
    "Check the image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alleged-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train[444].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-twenty",
   "metadata": {},
   "source": [
    "Visualize one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "positive-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[444])\n",
    "plt.imshow(x_train[444]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "animated-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-filing",
   "metadata": {},
   "source": [
    "Instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "genetic-centre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[444]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-education",
   "metadata": {},
   "source": [
    "Convert to float and scale the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "familiar-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-smith",
   "metadata": {},
   "source": [
    "Build a CNN using Keras Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "understanding-milan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cu\\anaconda3\\envs\\test\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │        \u001b[38;5;34m25,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m147,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">181,162</span> (707.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m181,162\u001b[0m (707.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">181,162</span> (707.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m181,162\u001b[0m (707.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "\n",
    "## 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "## Flatten turns 3x3x32 into 288x1\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(512))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-portable",
   "metadata": {},
   "source": [
    "* Use batch size of 32\n",
    "* Initiate RMSprop optimizer\n",
    "* Train the model using RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "removed-memorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.2907 - loss: 1.9277 - val_accuracy: 0.4826 - val_loss: 1.4184\n",
      "Epoch 2/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4657 - loss: 1.4837 - val_accuracy: 0.5370 - val_loss: 1.3040\n",
      "Epoch 3/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5110 - loss: 1.3648 - val_accuracy: 0.5603 - val_loss: 1.2163\n",
      "Epoch 4/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.5412 - loss: 1.2944 - val_accuracy: 0.5795 - val_loss: 1.1743\n",
      "Epoch 5/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.5623 - loss: 1.2332 - val_accuracy: 0.5873 - val_loss: 1.1747\n",
      "Epoch 6/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.5751 - loss: 1.1987 - val_accuracy: 0.6019 - val_loss: 1.1164\n",
      "Epoch 7/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5894 - loss: 1.1637 - val_accuracy: 0.6002 - val_loss: 1.1381\n",
      "Epoch 8/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6035 - loss: 1.1334 - val_accuracy: 0.6027 - val_loss: 1.1002\n",
      "Epoch 9/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.6082 - loss: 1.1165 - val_accuracy: 0.6345 - val_loss: 1.0435\n",
      "Epoch 10/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6131 - loss: 1.1077 - val_accuracy: 0.6227 - val_loss: 1.0902\n",
      "Epoch 11/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6226 - loss: 1.0949 - val_accuracy: 0.6130 - val_loss: 1.1402\n",
      "Epoch 12/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6251 - loss: 1.0790 - val_accuracy: 0.6264 - val_loss: 1.0856\n",
      "Epoch 13/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6299 - loss: 1.0678 - val_accuracy: 0.6493 - val_loss: 1.0160\n",
      "Epoch 14/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6327 - loss: 1.0660 - val_accuracy: 0.6451 - val_loss: 1.0299\n",
      "Epoch 15/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6375 - loss: 1.0596 - val_accuracy: 0.6112 - val_loss: 1.1923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24856fdc1d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0005)\n",
    "\n",
    "\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-lambda",
   "metadata": {},
   "source": [
    "#### Supplementary Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-theater",
   "metadata": {},
   "source": [
    "* Build a more complicated model with the following pattern:\n",
    "Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
    "\n",
    "* Use strides of 1 for all convolutional layers.\n",
    "\n",
    "* Write the number of parameters of your model  and compare it to the previous model\n",
    "\n",
    "* Train it for 5 epochs. Commpare the training time, loss and accuracy numbers (on both the training and validation sets)?\n",
    "\n",
    "* Use different structures and run times, and see how accurate your model can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "841cba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f50988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4415fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Getting the CIFAR10 dataset and creating a dataloader\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f3bf688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b0c7bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Flatten(start_dim=1, end_dim=-1)\n",
      "    (11): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the Neural Network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(128, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1bdb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X.to(device))\n",
    "        loss = loss_fn(pred, y.to(device))\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.to(device))\n",
    "            test_loss += loss_fn(pred, y.to(device)).item()\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c9a4cfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.307809  [   64/50000]\n",
      "loss: 2.305160  [ 6464/50000]\n",
      "loss: 2.297883  [12864/50000]\n",
      "loss: 2.308858  [19264/50000]\n",
      "loss: 2.303922  [25664/50000]\n",
      "loss: 2.304039  [32064/50000]\n",
      "loss: 2.301933  [38464/50000]\n",
      "loss: 2.295412  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 10.3%, Avg loss: 2.302668 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.306382  [   64/50000]\n",
      "loss: 2.304052  [ 6464/50000]\n",
      "loss: 2.296842  [12864/50000]\n",
      "loss: 2.307552  [19264/50000]\n",
      "loss: 2.302254  [25664/50000]\n",
      "loss: 2.302685  [32064/50000]\n",
      "loss: 2.300425  [38464/50000]\n",
      "loss: 2.295845  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 12.8%, Avg loss: 2.301470 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.305499  [   64/50000]\n",
      "loss: 2.303321  [ 6464/50000]\n",
      "loss: 2.296078  [12864/50000]\n",
      "loss: 2.306603  [19264/50000]\n",
      "loss: 2.300703  [25664/50000]\n",
      "loss: 2.301379  [32064/50000]\n",
      "loss: 2.299004  [38464/50000]\n",
      "loss: 2.296086  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 11.5%, Avg loss: 2.300224 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.304667  [   64/50000]\n",
      "loss: 2.302541  [ 6464/50000]\n",
      "loss: 2.295066  [12864/50000]\n",
      "loss: 2.305577  [19264/50000]\n",
      "loss: 2.298904  [25664/50000]\n",
      "loss: 2.299686  [32064/50000]\n",
      "loss: 2.297313  [38464/50000]\n",
      "loss: 2.296063  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 13.3%, Avg loss: 2.298594 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.303842  [   64/50000]\n",
      "loss: 2.301637  [ 6464/50000]\n",
      "loss: 2.293542  [12864/50000]\n",
      "loss: 2.304198  [19264/50000]\n",
      "loss: 2.296494  [25664/50000]\n",
      "loss: 2.297430  [32064/50000]\n",
      "loss: 2.294997  [38464/50000]\n",
      "loss: 2.295549  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 15.9%, Avg loss: 2.296294 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b8345499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Conv2d(3, 512, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "    (10): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a 2nd Neural Network, changing the output sizes and adding batch normalization\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(3, 512, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(512, 256, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model2 = NeuralNetwork().to(device)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "420e6c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.309057  [   64/50000]\n",
      "loss: 2.229287  [ 6464/50000]\n",
      "loss: 2.100967  [12864/50000]\n",
      "loss: 2.106111  [19264/50000]\n",
      "loss: 2.088027  [25664/50000]\n",
      "loss: 2.034389  [32064/50000]\n",
      "loss: 1.908281  [38464/50000]\n",
      "loss: 1.860714  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.3%, Avg loss: 1.823734 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.904580  [   64/50000]\n",
      "loss: 1.827310  [ 6464/50000]\n",
      "loss: 1.580456  [12864/50000]\n",
      "loss: 1.808307  [19264/50000]\n",
      "loss: 1.784313  [25664/50000]\n",
      "loss: 1.762202  [32064/50000]\n",
      "loss: 1.648149  [38464/50000]\n",
      "loss: 1.620634  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 1.612646 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.715846  [   64/50000]\n",
      "loss: 1.632957  [ 6464/50000]\n",
      "loss: 1.353631  [12864/50000]\n",
      "loss: 1.635789  [19264/50000]\n",
      "loss: 1.589655  [25664/50000]\n",
      "loss: 1.606805  [32064/50000]\n",
      "loss: 1.534886  [38464/50000]\n",
      "loss: 1.515792  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.501963 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.608960  [   64/50000]\n",
      "loss: 1.505099  [ 6464/50000]\n",
      "loss: 1.243910  [12864/50000]\n",
      "loss: 1.500372  [19264/50000]\n",
      "loss: 1.472464  [25664/50000]\n",
      "loss: 1.512770  [32064/50000]\n",
      "loss: 1.464502  [38464/50000]\n",
      "loss: 1.441351  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.9%, Avg loss: 1.426745 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.525280  [   64/50000]\n",
      "loss: 1.417696  [ 6464/50000]\n",
      "loss: 1.164197  [12864/50000]\n",
      "loss: 1.401573  [19264/50000]\n",
      "loss: 1.377838  [25664/50000]\n",
      "loss: 1.443951  [32064/50000]\n",
      "loss: 1.407712  [38464/50000]\n",
      "loss: 1.375866  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 1.368776 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Performing training with the same parameters\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model2, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model2, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c0c7c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Conv2d(3, 1024, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "    (10): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a 2nd Neural Network, changing the output sizes and adding batch normalization\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(3, 1024, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(1024, 512, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 256, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model3 = NeuralNetwork().to(device)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e0f2f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.313368  [   64/50000]\n",
      "loss: 2.154147  [ 6464/50000]\n",
      "loss: 1.995796  [12864/50000]\n",
      "loss: 2.014356  [19264/50000]\n",
      "loss: 1.951919  [25664/50000]\n",
      "loss: 1.893770  [32064/50000]\n",
      "loss: 1.759783  [38464/50000]\n",
      "loss: 1.728771  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.684078 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.783697  [   64/50000]\n",
      "loss: 1.671048  [ 6464/50000]\n",
      "loss: 1.418986  [12864/50000]\n",
      "loss: 1.719450  [19264/50000]\n",
      "loss: 1.545919  [25664/50000]\n",
      "loss: 1.627324  [32064/50000]\n",
      "loss: 1.569873  [38464/50000]\n",
      "loss: 1.545595  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.505243 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.585192  [   64/50000]\n",
      "loss: 1.480363  [ 6464/50000]\n",
      "loss: 1.217970  [12864/50000]\n",
      "loss: 1.520186  [19264/50000]\n",
      "loss: 1.368371  [25664/50000]\n",
      "loss: 1.489359  [32064/50000]\n",
      "loss: 1.461268  [38464/50000]\n",
      "loss: 1.419000  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.409609 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.468031  [   64/50000]\n",
      "loss: 1.347878  [ 6464/50000]\n",
      "loss: 1.105551  [12864/50000]\n",
      "loss: 1.378667  [19264/50000]\n",
      "loss: 1.262220  [25664/50000]\n",
      "loss: 1.398601  [32064/50000]\n",
      "loss: 1.373259  [38464/50000]\n",
      "loss: 1.320020  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.343321 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.384467  [   64/50000]\n",
      "loss: 1.250492  [ 6464/50000]\n",
      "loss: 1.027681  [12864/50000]\n",
      "loss: 1.276292  [19264/50000]\n",
      "loss: 1.188893  [25664/50000]\n",
      "loss: 1.327312  [32064/50000]\n",
      "loss: 1.307052  [38464/50000]\n",
      "loss: 1.242919  [44864/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 1.292876 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Performing training with the same parameters\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model3.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model3, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model3, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-still",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-jackson",
   "metadata": {},
   "source": [
    "I can conclude that I have learned how Convolutional Neural Networks work, and its implementation in Pytorch for the supplementary exercise, comparing the accuracies, it can be seen that the first and second model had worse accuracies (with the second model having slightly less difference) compared to the original architecture. This suggests that adding more layers does not necessarily increase accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
