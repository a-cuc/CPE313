{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d085328f",
   "metadata": {},
   "source": [
    "## Part 1: Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515a1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557f0048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Test if GPU is available\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8473e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root_dir, seq_len=16, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.seq_len = seq_len\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Map class names to numeric labels\n",
    "        classes = sorted(entry.name for entry in os.scandir(root_dir) if entry.is_dir())\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
    "        \n",
    "        # Build a list of all videos: each as (video_id, [frame_paths], label)\n",
    "        self.video_list = []\n",
    "        for cls_name in classes:\n",
    "            cls_dir = os.path.join(root_dir, cls_name)\n",
    "            # Find all images in this class folder\n",
    "            all_imgs = glob.glob(os.path.join(cls_dir, '*.jpg'))\n",
    "            # Group images by video ID prefix (e.g. '001' in '001_frame0.jpg')\n",
    "            groups = {}\n",
    "            for img_path in all_imgs:\n",
    "                filename = os.path.basename(img_path)\n",
    "                # Assume video ID is everything before first underscore\n",
    "                vid = filename.split('_')[0]\n",
    "                groups.setdefault(vid, []).append(img_path)\n",
    "            # Convert each group to (video_id, sorted_paths, label)\n",
    "            for vid, frame_paths in groups.items():\n",
    "                # Sort frames by numeric index after 'frame'\n",
    "                frame_paths.sort(key=lambda x: int(os.path.splitext(x)[0].split('_frame')[-1]))\n",
    "                label = self.class_to_idx[cls_name]\n",
    "                self.video_list.append((vid, frame_paths, label))\n",
    "        \n",
    "        # Optionally, sort video_list by video ID or shuffle as needed\n",
    "        self.video_list.sort(key=lambda x: x[0])  # sort by video_id (string)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        vid, frame_paths, label = self.video_list[idx]\n",
    "        selected_paths = frame_paths\n",
    "\n",
    "        # Load images and apply transforms\n",
    "        frames = []\n",
    "        for img_path in selected_paths:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                img = self.transform(img) \n",
    "            else:\n",
    "                img = transforms.ToTensor()(img)\n",
    "            frames.append(img)\n",
    "        # Stack into a tensor of shape (T, C, H, W)\n",
    "        video_tensor = torch.stack(frames, dim=0).to(device)\n",
    "        return video_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30728b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Instantiate dataset\n",
    "dataset = VideoDataset(root_dir=\"cnn-lstm-project-5\", seq_len=24, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8083016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training loop and model evaluation functions\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        y = y.to(device).float()\n",
    "        with autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            pred = model(X.to(device))\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation - modified to use mixed precision\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predicted_classes = (pred > 0).float()\n",
    "        correct += (predicted_classes == y).type(torch.float).sum().item()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    correct /= size\n",
    "    print(f\"Training Accuracy: {(100*correct):>0.1f}%\")\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            y = y.to(device).float()\n",
    "            # Using mixed precision for testing\n",
    "            with autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                pred = model(X.to(device))\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "            predicted_classes = (pred > 0).float()\n",
    "            correct += (predicted_classes == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ffa2f3",
   "metadata": {},
   "source": [
    "## Model 1: Custom\n",
    "\n",
    "Last Recorded Training Accuracy: 92.7%\n",
    "\n",
    "Last Recorded Testing Accuracy: 95.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39efc43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork_Hyper(\n",
      "  (cnn_layer): Sequential(\n",
      "    (0): ParametrizedConv3d(\n",
      "      3, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False\n",
      "      (parametrizations): ModuleDict(\n",
      "        (weight): ParametrizationList(\n",
      "          (0): _WeightNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): ParametrizedConv3d(\n",
      "      16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2, bias=False\n",
      "      (parametrizations): ModuleDict(\n",
      "        (weight): ParametrizationList(\n",
      "          (0): _WeightNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): ParametrizedConv3d(\n",
      "      32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2, bias=False\n",
      "      (parametrizations): ModuleDict(\n",
      "        (weight): ParametrizationList(\n",
      "          (0): _WeightNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): ParametrizedConv3d(\n",
      "      32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2, bias=False\n",
      "      (parametrizations): ModuleDict(\n",
      "        (weight): ParametrizationList(\n",
      "          (0): _WeightNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "    (14): ReLU()\n",
      "    (15): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): ParametrizedConv3d(\n",
      "      64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2, bias=False\n",
      "      (parametrizations): ModuleDict(\n",
      "        (weight): ParametrizationList(\n",
      "          (0): _WeightNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "    (18): ReLU()\n",
      "    (19): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (20): ParametrizedConv3d(\n",
      "      64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2, bias=False\n",
      "      (parametrizations): ModuleDict(\n",
      "        (weight): ParametrizationList(\n",
      "          (0): _WeightNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (21): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "    (22): ReLU()\n",
      "    (23): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): ParametrizedConv3d(\n",
      "      128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2, bias=False\n",
      "      (parametrizations): ModuleDict(\n",
      "        (weight): ParametrizationList(\n",
      "          (0): _WeightNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (25): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "    (26): ReLU()\n",
      "    (27): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (lstm_layer): LSTM(128, 64, num_layers=3, batch_first=True, dropout=0.3)\n",
      "  (fc_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# From Model 1 Attempt 10, I added changes to the model architecture\n",
    "# I decided to use Conv3D instead of Conv2D, where the additional dimension is the sequence\n",
    "from torch.nn.utils.parametrizations import weight_norm\n",
    "\n",
    "class NeuralNetwork_Hyper(nn.Module):\n",
    "    def __init__(self, lstm_h=64):\n",
    "        super().__init__()\n",
    "        self.cnn_layer = nn.Sequential(\n",
    "            weight_norm(nn.Conv3d(3, 16, 3, bias=False, padding=1)),\n",
    "            nn.GroupNorm(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            weight_norm(nn.Conv3d(16, 32, 3, bias=False, padding=1, groups=2)),\n",
    "            nn.GroupNorm(8, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            weight_norm(nn.Conv3d(32, 32, 3, bias=False, padding=1, groups=2)),\n",
    "            nn.GroupNorm(8, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            weight_norm(nn.Conv3d(32, 64, 3, bias=False, padding=1, groups=2)),\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            weight_norm(nn.Conv3d(64, 64, 3, bias=False, padding=1, groups=2)),\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            weight_norm(nn.Conv3d(64, 128, 3, bias=False, padding=1, groups=2)),\n",
    "            nn.GroupNorm(8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            weight_norm(nn.Conv3d(128, 128, 3, bias=False, padding=1, groups=2)),\n",
    "            nn.GroupNorm(8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2)),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        self.lstm_layer = nn.LSTM(input_size=128, hidden_size=lstm_h, num_layers=3,\n",
    "                                  dropout=0.3, batch_first=True)\n",
    "        self.fc_layer = nn.Linear(lstm_h, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape for CNN input\n",
    "        batch_size, sequence, channels, height, width = x.size()\n",
    "        x = x.view(batch_size, channels, sequence, height, width)\n",
    "        x = self.cnn_layer(x)\n",
    "\n",
    "\n",
    "        # Reshape for LSTM input\n",
    "        x = x.view(batch_size, sequence, -1)\n",
    "        output, (h_n, c_n) = self.lstm_layer(x)\n",
    "        logits = self.fc_layer(h_n[-1])\n",
    "        return logits.squeeze(1)\n",
    "\n",
    "model = NeuralNetwork_Hyper().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c655c147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 1/6\n",
      "loss: 0.694594  [    8/   96]\n",
      "Training Accuracy: 49.0%\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 0.693159 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.694680  [    8/   96]\n",
      "Training Accuracy: 41.7%\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 0.694368 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.690033  [    8/   96]\n",
      "Training Accuracy: 50.0%\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 0.694965 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.697494  [    8/   96]\n",
      "Training Accuracy: 39.6%\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 0.692042 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.691379  [    8/   96]\n",
      "Training Accuracy: 52.1%\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 0.693462 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.692429  [    8/   96]\n",
      "Training Accuracy: 52.1%\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 0.694408 \n",
      "\n",
      "Done with fold 1\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 1/6\n",
      "loss: 0.696270  [    8/   96]\n",
      "Training Accuracy: 44.8%\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 0.693090 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.693749  [    8/   96]\n",
      "Training Accuracy: 60.4%\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.693605 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.690671  [    8/   96]\n",
      "Training Accuracy: 64.6%\n",
      "Test Error: \n",
      " Accuracy: 41.7%, Avg loss: 0.694848 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.687561  [    8/   96]\n",
      "Training Accuracy: 60.4%\n",
      "Test Error: \n",
      " Accuracy: 41.7%, Avg loss: 0.726829 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.631538  [    8/   96]\n",
      "Training Accuracy: 67.7%\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 0.725505 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.585953  [    8/   96]\n",
      "Training Accuracy: 72.9%\n",
      "Test Error: \n",
      " Accuracy: 41.7%, Avg loss: 0.844910 \n",
      "\n",
      "Done with fold 2\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 1/6\n",
      "loss: 0.358675  [    8/   96]\n",
      "Training Accuracy: 66.7%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.607401 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.651916  [    8/   96]\n",
      "Training Accuracy: 75.0%\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.602131 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.432338  [    8/   96]\n",
      "Training Accuracy: 78.1%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.620509 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.529131  [    8/   96]\n",
      "Training Accuracy: 78.1%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.668170 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.215105  [    8/   96]\n",
      "Training Accuracy: 83.3%\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.639287 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.330117  [    8/   96]\n",
      "Training Accuracy: 83.3%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.748710 \n",
      "\n",
      "Done with fold 3\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 1/6\n",
      "loss: 0.844742  [    8/   96]\n",
      "Training Accuracy: 55.2%\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 0.623169 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.513080  [    8/   96]\n",
      "Training Accuracy: 68.8%\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.594351 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.521140  [    8/   96]\n",
      "Training Accuracy: 77.1%\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.555126 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.414274  [    8/   96]\n",
      "Training Accuracy: 79.2%\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.448980 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.358770  [    8/   96]\n",
      "Training Accuracy: 83.3%\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.486368 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.516320  [    8/   96]\n",
      "Training Accuracy: 85.4%\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.455894 \n",
      "\n",
      "Done with fold 4\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 1/6\n",
      "loss: 0.287034  [    8/   96]\n",
      "Training Accuracy: 74.0%\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.377107 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.346844  [    8/   96]\n",
      "Training Accuracy: 78.1%\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.328438 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.423690  [    8/   96]\n",
      "Training Accuracy: 82.3%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.249202 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.450828  [    8/   96]\n",
      "Training Accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.198983 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.156110  [    8/   96]\n",
      "Training Accuracy: 86.5%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.205396 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.416569  [    8/   96]\n",
      "Training Accuracy: 92.7%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.169611 \n",
      "\n",
      "Done with fold 5\n",
      "KFold cross-validation complete!\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Enabling NVIDIA cuDNN auto-tuner\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "num_videos = len(dataset)\n",
    "video_indices = np.arange(num_videos)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "batch_size = 8\n",
    "num_epochs = 6\n",
    "learning_rate = 1e-3\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(video_indices)):\n",
    "    print(f\"\\n===== Fold {fold+1} =====\")\n",
    "    train_set = Subset(dataset, train_idx)\n",
    "    test_set = Subset(dataset, test_idx)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Re-initialize optimizer, scheduler for each fold\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=3)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        train_loop(train_loader, model, loss_fn, optimizer)\n",
    "        test_loop(test_loader, model, loss_fn)\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Done with fold {fold+1}\")\n",
    "\n",
    "print(\"KFold cross-validation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a2c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model weights as reference\n",
    "torch.save(model.state_dict(), \"model1_new_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70872a5b",
   "metadata": {},
   "source": [
    "## Model 2: EfficientNet\n",
    "\n",
    "Last Recorded Training Accuracy: 97.9%\n",
    "\n",
    "Last Recorded Testing Accuracy: 95.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2265defb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.005, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.01, mode=row)\n",
       "      )\n",
       "      (1): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.015000000000000003, mode=row)\n",
       "      )\n",
       "      (2): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02, mode=row)\n",
       "      )\n",
       "      (3): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.030000000000000006, mode=row)\n",
       "      )\n",
       "      (1): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.035, mode=row)\n",
       "      )\n",
       "      (2): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
       "      )\n",
       "      (3): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.045, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06000000000000001, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.065, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.075, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "            (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.085, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.095, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10500000000000001, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11000000000000001, mode=row)\n",
       "      )\n",
       "      (7): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11500000000000002, mode=row)\n",
       "      )\n",
       "      (8): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12000000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.135, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14500000000000002, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.155, mode=row)\n",
       "      )\n",
       "      (7): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
       "      )\n",
       "      (8): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.165, mode=row)\n",
       "      )\n",
       "      (9): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17, mode=row)\n",
       "      )\n",
       "      (10): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.175, mode=row)\n",
       "      )\n",
       "      (11): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18, mode=row)\n",
       "      )\n",
       "      (12): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.185, mode=row)\n",
       "      )\n",
       "      (13): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.19, mode=row)\n",
       "      )\n",
       "      (14): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.195, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Conv2dNormActivation(\n",
       "      (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomFineTuneModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(CustomFineTuneModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.lstm_layer = nn.LSTM(input_size=1280, hidden_size=64, batch_first=True)\n",
    "        self.final_classifier = nn.Linear(64, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence, channels, height, width = x.size()\n",
    "        x = x.view(batch_size * sequence, channels, height, width)\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        x = x.view(batch_size, sequence, -1)  # Reshape for LSTM input\n",
    "        output, (h_n, c_n) = self.lstm_layer(x)\n",
    "        x = self.final_classifier(h_n.squeeze(0))\n",
    "        return x.squeeze()\n",
    "\n",
    "# Create an instance of the custom model\n",
    "model2_ft1 = models.efficientnet_v2_s(weights='DEFAULT')\n",
    "model2_ft1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61db2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Fixed Feature Extraction\n",
    "\n",
    "for param in model2_ft1.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe6804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_ft1.classifier = nn.Identity()  # Remove the final classification layer\n",
    "model2_ft1 = CustomFineTuneModel(model2_ft1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac95f1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 1/6\n",
      "loss: 0.655065  [    8/   96]\n",
      "Training Accuracy: 50.0%\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 0.701501 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.680434  [    8/   96]\n",
      "Training Accuracy: 65.6%\n",
      "Test Error: \n",
      " Accuracy: 41.7%, Avg loss: 0.716992 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.599751  [    8/   96]\n",
      "Training Accuracy: 71.9%\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 0.738910 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.625346  [    8/   96]\n",
      "Training Accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 41.7%, Avg loss: 0.771145 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.547474  [    8/   96]\n",
      "Training Accuracy: 83.3%\n",
      "Test Error: \n",
      " Accuracy: 33.3%, Avg loss: 0.842587 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.582722  [    8/   96]\n",
      "Training Accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 29.2%, Avg loss: 0.905157 \n",
      "\n",
      "Done with fold 1\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 1/6\n",
      "loss: 0.455884  [    8/   96]\n",
      "Training Accuracy: 70.8%\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.430945 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.547609  [    8/   96]\n",
      "Training Accuracy: 86.5%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.420914 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.517664  [    8/   96]\n",
      "Training Accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.375156 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.554965  [    8/   96]\n",
      "Training Accuracy: 88.5%\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.385181 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.381148  [    8/   96]\n",
      "Training Accuracy: 88.5%\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.420495 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.200890  [    8/   96]\n",
      "Training Accuracy: 94.8%\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.387640 \n",
      "\n",
      "Done with fold 2\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 1/6\n",
      "loss: 0.158566  [    8/   96]\n",
      "Training Accuracy: 82.3%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.235226 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.192550  [    8/   96]\n",
      "Training Accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.311861 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.237313  [    8/   96]\n",
      "Training Accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.284749 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.190433  [    8/   96]\n",
      "Training Accuracy: 95.8%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.271619 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.135543  [    8/   96]\n",
      "Training Accuracy: 96.9%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.288935 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.155982  [    8/   96]\n",
      "Training Accuracy: 90.6%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.292375 \n",
      "\n",
      "Done with fold 3\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 1/6\n",
      "loss: 0.460374  [    8/   96]\n",
      "Training Accuracy: 88.5%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.162399 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.142450  [    8/   96]\n",
      "Training Accuracy: 94.8%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.151060 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.204577  [    8/   96]\n",
      "Training Accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.148615 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.125513  [    8/   96]\n",
      "Training Accuracy: 94.8%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.199395 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.205974  [    8/   96]\n",
      "Training Accuracy: 94.8%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.176263 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.162170  [    8/   96]\n",
      "Training Accuracy: 95.8%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.172617 \n",
      "\n",
      "Done with fold 4\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 1/6\n",
      "loss: 0.279884  [    8/   96]\n",
      "Training Accuracy: 92.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.090599 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.616603  [    8/   96]\n",
      "Training Accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.088001 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.139075  [    8/   96]\n",
      "Training Accuracy: 96.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.075074 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.080079  [    8/   96]\n",
      "Training Accuracy: 97.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.081187 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.038205  [    8/   96]\n",
      "Training Accuracy: 97.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.094500 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.070327  [    8/   96]\n",
      "Training Accuracy: 97.9%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.093897 \n",
      "\n",
      "Done with fold 5\n",
      "KFold cross-validation complete!\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Enabling NVIDIA cuDNN auto-tuner\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "num_videos = len(dataset)\n",
    "video_indices = np.arange(num_videos)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "batch_size = 8\n",
    "num_epochs = 6\n",
    "learning_rate = 1e-3\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(video_indices)):\n",
    "    print(f\"\\n===== Fold {fold+1} =====\")\n",
    "    train_set = Subset(dataset, train_idx)\n",
    "    test_set = Subset(dataset, test_idx)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Re-initialize optimizer, scheduler for each fold\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model2_ft1.parameters(), lr=learning_rate)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        train_loop(train_loader, model2_ft1, loss_fn, optimizer)\n",
    "        test_loop(test_loader, model2_ft1, loss_fn)\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Done with fold {fold+1}\")\n",
    "\n",
    "print(\"KFold cross-validation complete!\")\n",
    "\n",
    "# Training took 17 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57dc167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights as reference\n",
    "torch.save(model2_ft1.state_dict(), \"model2_new_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04901779",
   "metadata": {},
   "source": [
    "## Model 3: ShuffleNet\n",
    "\n",
    "Last Recorded Training Accuracy: 96.9%\n",
    "\n",
    "Last Recorded Testing Accuracy: 95.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27aa7e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShuffleNetV2(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (stage2): Sequential(\n",
       "    (0): InvertedResidual(\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=88, bias=False)\n",
       "        (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "        (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "        (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "        (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage3): Sequential(\n",
       "    (0): InvertedResidual(\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv2d(176, 176, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=176, bias=False)\n",
       "        (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=176, bias=False)\n",
       "        (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "        (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "        (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "        (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "        (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "        (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "        (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "        (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage4): Sequential(\n",
       "    (0): InvertedResidual(\n",
       "      (branch1): Sequential(\n",
       "        (0): Conv2d(352, 352, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=352, bias=False)\n",
       "        (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(352, 352, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=352, bias=False)\n",
       "        (4): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352, bias=False)\n",
       "        (4): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352, bias=False)\n",
       "        (4): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (branch1): Sequential()\n",
       "      (branch2): Sequential(\n",
       "        (0): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352, bias=False)\n",
       "        (4): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (6): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(704, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model_3 = models.shufflenet_v2_x1_5(weights='DEFAULT') # Using the 1.5x output channel model\n",
    "model_3.to(device)\n",
    "\n",
    "model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a35353b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR Fixed Feature Extraction\n",
    "\n",
    "for param in model_3.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1fffc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomFineTuneModel(\n",
       "  (base_model): ShuffleNetV2(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (stage2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=88, bias=False)\n",
       "          (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(88, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(176, 176, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=176, bias=False)\n",
       "          (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=176, bias=False)\n",
       "          (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "          (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "          (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "          (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "          (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "          (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "          (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n",
       "          (4): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(176, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(352, 352, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=352, bias=False)\n",
       "          (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(352, 352, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=352, bias=False)\n",
       "          (4): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352, bias=False)\n",
       "          (4): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352, bias=False)\n",
       "          (4): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=352, bias=False)\n",
       "          (4): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(352, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(704, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (lstm_layer): LSTM(1024, 128, batch_first=True)\n",
       "  (final_classifier): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomFineTuneModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(CustomFineTuneModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.lstm_layer = nn.LSTM(input_size=1024, hidden_size=128, batch_first=True) # add dropout\n",
    "        self.final_classifier = nn.Linear(128, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence, channels, height, width = x.size()\n",
    "        x = x.view(batch_size * sequence, channels, height, width)\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        x = x.view(batch_size, sequence, -1)  # Reshape for LSTM input\n",
    "        output, (h_n, c_n) = self.lstm_layer(x)\n",
    "        x = self.final_classifier(h_n[-1])\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "# Create an instance of the custom model\n",
    "\n",
    "\n",
    "model_3.fc = nn.Identity()  # Remove the final classification layer\n",
    "model3_ft1 = CustomFineTuneModel(model_3).to(device)\n",
    "# Show the model architecture\n",
    "model3_ft1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce46c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 1/6\n",
      "loss: 0.242297  [    8/   96]\n",
      "Training Accuracy: 88.5%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.259191 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.318742  [    8/   96]\n",
      "Training Accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.245983 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.178621  [    8/   96]\n",
      "Training Accuracy: 88.5%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.232871 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.131113  [    8/   96]\n",
      "Training Accuracy: 95.8%\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.259693 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.423329  [    8/   96]\n",
      "Training Accuracy: 92.7%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.242034 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.113820  [    8/   96]\n",
      "Training Accuracy: 94.8%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.247724 \n",
      "\n",
      "Done with fold 1\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 1/6\n",
      "loss: 0.202168  [    8/   96]\n",
      "Training Accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.139055 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.137582  [    8/   96]\n",
      "Training Accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.150174 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.101083  [    8/   96]\n",
      "Training Accuracy: 94.8%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.167876 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.398574  [    8/   96]\n",
      "Training Accuracy: 94.8%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.137760 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.313585  [    8/   96]\n",
      "Training Accuracy: 97.9%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.160314 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.128845  [    8/   96]\n",
      "Training Accuracy: 94.8%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.149299 \n",
      "\n",
      "Done with fold 2\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 1/6\n",
      "loss: 0.075795  [    8/   96]\n",
      "Training Accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.074108 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.152081  [    8/   96]\n",
      "Training Accuracy: 90.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.083705 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.050356  [    8/   96]\n",
      "Training Accuracy: 84.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.083943 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.161073  [    8/   96]\n",
      "Training Accuracy: 86.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.096003 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.458779  [    8/   96]\n",
      "Training Accuracy: 94.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.098885 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.189840  [    8/   96]\n",
      "Training Accuracy: 96.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.095695 \n",
      "\n",
      "Done with fold 3\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 1/6\n",
      "loss: 0.191515  [    8/   96]\n",
      "Training Accuracy: 94.8%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.143328 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.104076  [    8/   96]\n",
      "Training Accuracy: 96.9%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.121840 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.120346  [    8/   96]\n",
      "Training Accuracy: 99.0%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.108318 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.165605  [    8/   96]\n",
      "Training Accuracy: 99.0%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.101132 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.067035  [    8/   96]\n",
      "Training Accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.064062 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.077020  [    8/   96]\n",
      "Training Accuracy: 97.9%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.114085 \n",
      "\n",
      "Done with fold 4\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 1/6\n",
      "loss: 0.081896  [    8/   96]\n",
      "Training Accuracy: 97.9%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.113809 \n",
      "\n",
      "Epoch 2/6\n",
      "loss: 0.038635  [    8/   96]\n",
      "Training Accuracy: 94.8%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.126491 \n",
      "\n",
      "Epoch 3/6\n",
      "loss: 0.073446  [    8/   96]\n",
      "Training Accuracy: 96.9%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.121833 \n",
      "\n",
      "Epoch 4/6\n",
      "loss: 0.110435  [    8/   96]\n",
      "Training Accuracy: 97.9%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.109342 \n",
      "\n",
      "Epoch 5/6\n",
      "loss: 0.042474  [    8/   96]\n",
      "Training Accuracy: 99.0%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.121083 \n",
      "\n",
      "Epoch 6/6\n",
      "loss: 0.061866  [    8/   96]\n",
      "Training Accuracy: 96.9%\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.117381 \n",
      "\n",
      "Done with fold 5\n",
      "KFold cross-validation complete!\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Enabling NVIDIA cuDNN auto-tuner\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "num_videos = len(dataset)\n",
    "video_indices = np.arange(num_videos)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "batch_size = 8\n",
    "num_epochs = 6\n",
    "learning_rate = 1e-4\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(video_indices)):\n",
    "    print(f\"\\n===== Fold {fold+1} =====\")\n",
    "    train_set = Subset(dataset, train_idx)\n",
    "    test_set = Subset(dataset, test_idx)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Re-initialize optimizer, scheduler for each fold\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model3_ft1.parameters(), lr=learning_rate)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        train_loop(train_loader, model3_ft1, loss_fn, optimizer)\n",
    "        test_loop(test_loader, model3_ft1, loss_fn)\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Done with fold {fold+1}\")\n",
    "\n",
    "print(\"KFold cross-validation complete!\")\n",
    "\n",
    "# Training took 16 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model weights as reference\n",
    "torch.save(model3_ft1.state_dict(), \"model3_new_weights.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
